{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from custom_dataloader import replicate_data\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, roc_auc_score, RocCurveDisplay\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_estimate(estimator, X, Y, amounts_train, amounts_val, n_splits=100):\n",
    "                          \n",
    "    scoresA = []\n",
    "    scoresP = []\n",
    "    scoresR = []\n",
    "    \n",
    "    for n in range(0,n_splits):\n",
    "        inp_tr, tar_tr, inp_va, tar_va, inp_te, tar_te = replicate_data(X, Y, 'three', amounts_train, amounts_val, random.randint(0,1000))\n",
    "        scaler_S = StandardScaler().fit(inp_tr)\n",
    "        inp_tr = scaler_S.transform(inp_tr)\n",
    "        inp_va = scaler_S.transform(inp_va)\n",
    "        # inp_te = scaler_S.transform(inp_te)\n",
    "        estimator.fit(inp_tr, tar_tr.ravel())  \n",
    "        pred_va = estimator.predict(inp_va)\n",
    "        scoresA.append(accuracy_score(tar_va,pred_va))\n",
    "        scoresR.append(recall_score(tar_va,pred_va,average=None,zero_division=1))  \n",
    "        scoresP.append(precision_score(tar_va,pred_va,average=None,zero_division=1)) \n",
    "        \n",
    "    scoresR = list(map(list, zip(*scoresR)))\n",
    "    scoresP = list(map(list, zip(*scoresP)))\n",
    "\n",
    "    estimateA = np.mean(scoresA)*100.\n",
    "    stderrA = np.std(scoresA)*100.\n",
    "    \n",
    "    estimateR = [np.mean(scoresR[0])*100.,np.mean(scoresR[1])*100.,np.mean(scoresR[2])*100.]\n",
    "    stderrR = [np.std(scoresR[0])*100.,np.std(scoresR[1])*100.,np.std(scoresR[2])*100.]\n",
    "    \n",
    "    estimateP = [np.mean(scoresP[0])*100.,np.mean(scoresP[1])*100.,np.mean(scoresP[2])*100.]\n",
    "    stderrP = [np.std(scoresP[0])*100.,np.std(scoresP[1])*100.,np.std(scoresP[2])*100.]\n",
    "    \n",
    "    return estimateR, stderrR, estimateP, stderrP, estimateA, stderrA\n",
    "\n",
    "def bootstrap_to_file(file, estimator, X, Y, amounts_train, amounts_val, n_splits=200):\n",
    "    estR, stderrR, estP, stderrP, estA, stderrA = bootstrap_estimate(estimator, X, Y, amounts_train, amounts_val, n_splits=n_splits)\n",
    "    classes = [\"Class I\", \"Class II\", \"Contaminants\"]\n",
    "    for i, cl in enumerate(classes):\n",
    "        if i==1:\n",
    "            file.write(cl+\"& $\"+\"{:.1f}\".format(estR[i])+\"\\pm\"+\"{:.1f}\".format(stderrR[i])+\"$ & $\"+\n",
    "                \"{:.1f}\".format(estP[i])+\"\\pm\"+\"{:.1f}\".format(stderrP[i])+\"$ & $\"+\"{:.1f}\".format(estA)+\"\\pm\"+\"{:.1f}\".format(stderrA)+\"$ // \\n\")\n",
    "        else:\n",
    "            file.write(cl+\"& $\"+\"{:.1f}\".format(estR[i])+\"\\pm\"+\"{:.1f}\".format(stderrR[i])+\"$ & $\"+\n",
    "                \"{:.1f}\".format(estP[i])+\"\\pm\"+\"{:.1f}\".format(stderrP[i])+\"$&// \\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Set-Up\n",
    "\n",
    "# Train on SPICY classifications\n",
    "X = np.load(\"../Data_and_Results/Inputs_YSO_Train.npy\") # Load input data\n",
    "Y = np.load(\"../Data_and_Results/Targets_YSO_Train.npy\") # Load target data\n",
    "\n",
    "train_amount = [3000,3000,3000,3000]\n",
    "valid_amount = [6726,25687,10162,2300]\n",
    "\n",
    "inp_tr, tar_tr, inp_va, tar_va, inp_te, tar_te, train_ogtarget, valid_ogtarget, test_ogtarget = replicate_data(X, Y, Y, train_amount, valid_amount)\n",
    "\n",
    "# Test on \n",
    "inp_te = np.load(\"../Data_and_Results/Inputs_YSO_Test.npy\") # Load input data\n",
    "tar_te = np.load(\"../Data_and_Results/Targets_YSO_Test.npy\") # Load target data\n",
    "\n",
    "# scaling data according to training inputs\n",
    "scaler_S = StandardScaler().fit(inp_tr)\n",
    "inp_tr = scaler_S.transform(inp_tr)\n",
    "inp_va = scaler_S.transform(inp_va)\n",
    "inp_te = scaler_S.transform(inp_te) \n",
    "\n",
    "# custom_labs = ['YSO','EG','Star']\n",
    "custom_labs = ['Class I', 'Class II', 'Flat-Spectrum', 'Class III']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "boostcl = GradientBoostingClassifier(criterion='friedman_mse',max_depth=5,max_features='log2',\n",
    "                n_estimators=150,n_iter_no_change=5,subsample=1.0,warm_start=False)\n",
    "rfcl = RandomForestClassifier(class_weight='balanced',criterion='entropy',max_features='log2',n_estimators=50,oob_score=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier(max_depth=5, max_features='log2', n_estimators=150,\n",
       "                           n_iter_no_change=5)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boostcl.fit(inp_tr,tar_tr.ravel())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9364930580542611\n"
     ]
    }
   ],
   "source": [
    "pred_tr = boostcl.predict(inp_tr)\n",
    "pred_va = boostcl.predict(inp_va)\n",
    "pred_te = boostcl.predict(inp_te)\n",
    "\n",
    "scores_va = boostcl.predict_proba(inp_va)\n",
    "\n",
    "print(roc_auc_score(tar_va.ravel(),scores_va,multi_class='ovo'))\n",
    "\n",
    "# with open(\"../Data_and_Results/YSO_GB_Classification_Report.txt\",'w') as f:\n",
    "#     f.write(\"Training Set Report\")\n",
    "#     f.write(classification_report(tar_tr,pred_tr,target_names=custom_labs))\n",
    "#     f.write(\"Validation Set Report\")\n",
    "#     f.write(classification_report(tar_va,pred_va,target_names=custom_labs))\n",
    "#     f.write(\"Test Set Report\")\n",
    "#     f.write(classification_report(tar_te,pred_te,target_names=custom_labs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(class_weight='balanced', criterion='entropy',\n",
       "                       max_features='log2', n_estimators=50)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfcl.fit(inp_tr,tar_tr.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9348952888558216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/breannacrompvoets/miniforge3/envs/SF/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/breannacrompvoets/miniforge3/envs/SF/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/breannacrompvoets/miniforge3/envs/SF/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "pred_tr = rfcl.predict(inp_tr)\n",
    "pred_va = rfcl.predict(inp_va)\n",
    "pred_te = rfcl.predict(inp_te)\n",
    "scores_va = rfcl.predict_proba(inp_va)\n",
    "\n",
    "print(roc_auc_score(tar_va.ravel(),scores_va,multi_class='ovo'))\n",
    "\n",
    "with open(\"../Data_and_Results/YSO_RF_Classification_Report.txt\",'w') as f:\n",
    "    f.write(\"Training Set Report\")\n",
    "    f.write(classification_report(tar_tr,pred_tr,target_names=custom_labs))\n",
    "    f.write(\"Validation Set Report\")\n",
    "    f.write(classification_report(tar_va,pred_va,target_names=custom_labs))\n",
    "    f.write(\"Test Set Report\")\n",
    "    f.write(classification_report(tar_te,pred_te,target_names=custom_labs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a7a87715bbc43d8b5f73b6200b6ef66f163e7bfd9f5c97aea1eada326c99da2f"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 ('SF')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
