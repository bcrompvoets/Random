{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN - PHYS 555 Term Project - Sam and Breanna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data_utils\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on : cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Running on : {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (20177, 8) , (20177, 1) ------- Validation set: (6726, 8) , (6726, 1)\n"
     ]
    }
   ],
   "source": [
    "# data load\n",
    "X = np.load(\"Data/Input_Class_3Classes_Sep.npy\") # Load input data\n",
    "Y = np.load(\"Data/Target_Class_3Classes_Sep.npy\") # Load target data\n",
    "\n",
    "# splitting data\n",
    "inp_tr, inp_va, tar_tr, tar_va = train_test_split(X, Y, test_size=0.25)\n",
    "\n",
    "print(f'Training set: {inp_tr.shape} , {tar_tr.shape} ------- Validation set: {inp_va.shape} , {tar_va.shape}')\n",
    "\n",
    "# scaling data according to training inputs\n",
    "scaler_S = StandardScaler().fit(inp_tr)\n",
    "inp_tr = scaler_S.transform(inp_tr)\n",
    "inp_va = scaler_S.transform(inp_va)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8854140853446995\n"
     ]
    }
   ],
   "source": [
    "# checking labels\n",
    "#plt.hist(tar_tr)\n",
    "\n",
    "ind = len(np.where(tar_tr == 2)[0])\n",
    "print(ind/len(tar_tr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/PHYS555_PY37/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \n",
      "/opt/anaconda3/envs/PHYS555_PY37/lib/python3.7/site-packages/ipykernel_launcher.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/opt/anaconda3/envs/PHYS555_PY37/lib/python3.7/site-packages/ipykernel_launcher.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  after removing the cwd from sys.path.\n",
      "/opt/anaconda3/envs/PHYS555_PY37/lib/python3.7/site-packages/ipykernel_launcher.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# concatenate the labels onto the inputs for both training and validation\n",
    "inp_tr = torch.tensor(inp_tr)\n",
    "tar_tr = torch.tensor(tar_tr)\n",
    "inp_va = torch.tensor(inp_va)\n",
    "tar_va = torch.tensor(tar_va)\n",
    "\n",
    "train_data = data_utils.TensorDataset(inp_tr, tar_tr)\n",
    "test_data = data_utils.TensorDataset(inp_va, tar_va)\n",
    "\n",
    "# constructing data loaders for nn\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=50)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([-0.1199, -0.4571, -0.0471, -0.6029, -0.0378, -0.7544,  0.1209, -0.8241],\n",
      "       dtype=torch.float64), tensor([2], dtype=torch.int32))\n"
     ]
    }
   ],
   "source": [
    "# tester code to see if loaders are behaving properly\n",
    "for i in range(1):\n",
    "    item = train_loader.dataset.__getitem__(i)\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Replicate NN from Cornu Paper\n",
    "\n",
    "> What do they use?\n",
    "\n",
    "Sigmoid Activation function for the layer(s)\n",
    "Sum of squares difference for loss function\n",
    "Only one hidden layer\n",
    "Output layer must have 3 neurons to match classes amount\n",
    "Output layer has the softmax activation\n",
    "Input layer has a dimension of 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN - With one hidden layer\n",
    "class BaseMLP(nn.Module):\n",
    "    def __init__(self, input_size, n_hidden, output_size):\n",
    "        super(BaseMLP, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.n_hidden = n_hidden\n",
    "        self.output_size = output_size\n",
    "        self.fc1 = nn.Linear(self.input_size, self.n_hidden)\n",
    "        self.fc2 = nn.Linear(self.n_hidden, self.output_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        x = self.fc2(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_n_params(model):\n",
    "    np=0\n",
    "    for p in list(model.parameters()):\n",
    "        np += p.nelement()\n",
    "    return np\n",
    "\n",
    "learning_rate = 0.005\n",
    "mom = 0.9\n",
    "\n",
    "accuracy_list = []\n",
    "\n",
    "def train(epoch, model):\n",
    "    model.to(device)\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=mom)\n",
    "    print('Number of parameters: {}'.format(get_n_params(model)))\n",
    "\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # send to device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data.float())\n",
    "        loss = F.cross_entropy(output, target.squeeze(-1).long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Print out every 10 batches\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} \\\n",
    "({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
    "            \n",
    "def test(model):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    for data, target in test_loader:\n",
    "        # send to device\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        output = model(data.float())\n",
    "        test_loss += F.cross_entropy(output, target.squeeze(-1).long(), reduction='sum').item() # sum up batch loss                                                               \n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability                                                                 \n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    accuracy_list.append(accuracy)\n",
    "    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: \\\n",
    "    {correct}/{len(test_loader.dataset)} ({accuracy:.0f}%)\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 243\n",
      "Train Epoch: 0 [0/20177 (0%)]\tLoss: 1.174527\n",
      "Train Epoch: 0 [5000/20177 (25%)]\tLoss: 0.675737\n",
      "Train Epoch: 0 [10000/20177 (50%)]\tLoss: 0.739549\n",
      "Train Epoch: 0 [15000/20177 (74%)]\tLoss: 0.678168\n",
      "Train Epoch: 0 [20000/20177 (99%)]\tLoss: 0.657039\n",
      "\n",
      "Test set: Average loss: 0.6723, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 1 [0/20177 (0%)]\tLoss: 0.617834\n",
      "Train Epoch: 1 [5000/20177 (25%)]\tLoss: 0.655808\n",
      "Train Epoch: 1 [10000/20177 (50%)]\tLoss: 0.733940\n",
      "Train Epoch: 1 [15000/20177 (74%)]\tLoss: 0.674234\n",
      "Train Epoch: 1 [20000/20177 (99%)]\tLoss: 0.654233\n",
      "\n",
      "Test set: Average loss: 0.6697, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 2 [0/20177 (0%)]\tLoss: 0.614678\n",
      "Train Epoch: 2 [5000/20177 (25%)]\tLoss: 0.653828\n",
      "Train Epoch: 2 [10000/20177 (50%)]\tLoss: 0.732877\n",
      "Train Epoch: 2 [15000/20177 (74%)]\tLoss: 0.673183\n",
      "Train Epoch: 2 [20000/20177 (99%)]\tLoss: 0.653299\n",
      "\n",
      "Test set: Average loss: 0.6688, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 3 [0/20177 (0%)]\tLoss: 0.613615\n",
      "Train Epoch: 3 [5000/20177 (25%)]\tLoss: 0.653077\n",
      "Train Epoch: 3 [10000/20177 (50%)]\tLoss: 0.732432\n",
      "Train Epoch: 3 [15000/20177 (74%)]\tLoss: 0.672698\n",
      "Train Epoch: 3 [20000/20177 (99%)]\tLoss: 0.652832\n",
      "\n",
      "Test set: Average loss: 0.6684, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 4 [0/20177 (0%)]\tLoss: 0.613080\n",
      "Train Epoch: 4 [5000/20177 (25%)]\tLoss: 0.652682\n",
      "Train Epoch: 4 [10000/20177 (50%)]\tLoss: 0.732190\n",
      "Train Epoch: 4 [15000/20177 (74%)]\tLoss: 0.672419\n",
      "Train Epoch: 4 [20000/20177 (99%)]\tLoss: 0.652552\n",
      "\n",
      "Test set: Average loss: 0.6681, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 5 [0/20177 (0%)]\tLoss: 0.612758\n",
      "Train Epoch: 5 [5000/20177 (25%)]\tLoss: 0.652440\n",
      "Train Epoch: 5 [10000/20177 (50%)]\tLoss: 0.732037\n",
      "Train Epoch: 5 [15000/20177 (74%)]\tLoss: 0.672239\n",
      "Train Epoch: 5 [20000/20177 (99%)]\tLoss: 0.652365\n",
      "\n",
      "Test set: Average loss: 0.6679, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 6 [0/20177 (0%)]\tLoss: 0.612543\n",
      "Train Epoch: 6 [5000/20177 (25%)]\tLoss: 0.652275\n",
      "Train Epoch: 6 [10000/20177 (50%)]\tLoss: 0.731934\n",
      "Train Epoch: 6 [15000/20177 (74%)]\tLoss: 0.672113\n",
      "Train Epoch: 6 [20000/20177 (99%)]\tLoss: 0.652232\n",
      "\n",
      "Test set: Average loss: 0.6678, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 7 [0/20177 (0%)]\tLoss: 0.612389\n",
      "Train Epoch: 7 [5000/20177 (25%)]\tLoss: 0.652157\n",
      "Train Epoch: 7 [10000/20177 (50%)]\tLoss: 0.731858\n",
      "Train Epoch: 7 [15000/20177 (74%)]\tLoss: 0.672020\n",
      "Train Epoch: 7 [20000/20177 (99%)]\tLoss: 0.652133\n",
      "\n",
      "Test set: Average loss: 0.6677, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 8 [0/20177 (0%)]\tLoss: 0.612274\n",
      "Train Epoch: 8 [5000/20177 (25%)]\tLoss: 0.652068\n",
      "Train Epoch: 8 [10000/20177 (50%)]\tLoss: 0.731801\n",
      "Train Epoch: 8 [15000/20177 (74%)]\tLoss: 0.671949\n",
      "Train Epoch: 8 [20000/20177 (99%)]\tLoss: 0.652055\n",
      "\n",
      "Test set: Average loss: 0.6677, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 9 [0/20177 (0%)]\tLoss: 0.612184\n",
      "Train Epoch: 9 [5000/20177 (25%)]\tLoss: 0.651998\n",
      "Train Epoch: 9 [10000/20177 (50%)]\tLoss: 0.731757\n",
      "Train Epoch: 9 [15000/20177 (74%)]\tLoss: 0.671892\n",
      "Train Epoch: 9 [20000/20177 (99%)]\tLoss: 0.651993\n",
      "\n",
      "Test set: Average loss: 0.6676, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 10 [0/20177 (0%)]\tLoss: 0.612111\n",
      "Train Epoch: 10 [5000/20177 (25%)]\tLoss: 0.651942\n",
      "Train Epoch: 10 [10000/20177 (50%)]\tLoss: 0.731721\n",
      "Train Epoch: 10 [15000/20177 (74%)]\tLoss: 0.671847\n",
      "Train Epoch: 10 [20000/20177 (99%)]\tLoss: 0.651942\n",
      "\n",
      "Test set: Average loss: 0.6676, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 11 [0/20177 (0%)]\tLoss: 0.612052\n",
      "Train Epoch: 11 [5000/20177 (25%)]\tLoss: 0.651896\n",
      "Train Epoch: 11 [10000/20177 (50%)]\tLoss: 0.731692\n",
      "Train Epoch: 11 [15000/20177 (74%)]\tLoss: 0.671809\n",
      "Train Epoch: 11 [20000/20177 (99%)]\tLoss: 0.651900\n",
      "\n",
      "Test set: Average loss: 0.6675, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 12 [0/20177 (0%)]\tLoss: 0.612003\n",
      "Train Epoch: 12 [5000/20177 (25%)]\tLoss: 0.651858\n",
      "Train Epoch: 12 [10000/20177 (50%)]\tLoss: 0.731667\n",
      "Train Epoch: 12 [15000/20177 (74%)]\tLoss: 0.671777\n",
      "Train Epoch: 12 [20000/20177 (99%)]\tLoss: 0.651865\n",
      "\n",
      "Test set: Average loss: 0.6675, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 13 [0/20177 (0%)]\tLoss: 0.611961\n",
      "Train Epoch: 13 [5000/20177 (25%)]\tLoss: 0.651825\n",
      "Train Epoch: 13 [10000/20177 (50%)]\tLoss: 0.731647\n",
      "Train Epoch: 13 [15000/20177 (74%)]\tLoss: 0.671750\n",
      "Train Epoch: 13 [20000/20177 (99%)]\tLoss: 0.651834\n",
      "\n",
      "Test set: Average loss: 0.6675, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 14 [0/20177 (0%)]\tLoss: 0.611926\n",
      "Train Epoch: 14 [5000/20177 (25%)]\tLoss: 0.651798\n",
      "Train Epoch: 14 [10000/20177 (50%)]\tLoss: 0.731629\n",
      "Train Epoch: 14 [15000/20177 (74%)]\tLoss: 0.671727\n",
      "Train Epoch: 14 [20000/20177 (99%)]\tLoss: 0.651808\n",
      "\n",
      "Test set: Average loss: 0.6674, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 15 [0/20177 (0%)]\tLoss: 0.611894\n",
      "Train Epoch: 15 [5000/20177 (25%)]\tLoss: 0.651773\n",
      "Train Epoch: 15 [10000/20177 (50%)]\tLoss: 0.731614\n",
      "Train Epoch: 15 [15000/20177 (74%)]\tLoss: 0.671707\n",
      "Train Epoch: 15 [20000/20177 (99%)]\tLoss: 0.651785\n",
      "\n",
      "Test set: Average loss: 0.6674, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 16 [0/20177 (0%)]\tLoss: 0.611867\n",
      "Train Epoch: 16 [5000/20177 (25%)]\tLoss: 0.651752\n",
      "Train Epoch: 16 [10000/20177 (50%)]\tLoss: 0.731601\n",
      "Train Epoch: 16 [15000/20177 (74%)]\tLoss: 0.671689\n",
      "Train Epoch: 16 [20000/20177 (99%)]\tLoss: 0.651764\n",
      "\n",
      "Test set: Average loss: 0.6674, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 17 [0/20177 (0%)]\tLoss: 0.611843\n",
      "Train Epoch: 17 [5000/20177 (25%)]\tLoss: 0.651734\n",
      "Train Epoch: 17 [10000/20177 (50%)]\tLoss: 0.731589\n",
      "Train Epoch: 17 [15000/20177 (74%)]\tLoss: 0.671673\n",
      "Train Epoch: 17 [20000/20177 (99%)]\tLoss: 0.651746\n",
      "\n",
      "Test set: Average loss: 0.6674, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 18 [0/20177 (0%)]\tLoss: 0.611822\n",
      "Train Epoch: 18 [5000/20177 (25%)]\tLoss: 0.651717\n",
      "Train Epoch: 18 [10000/20177 (50%)]\tLoss: 0.731579\n",
      "Train Epoch: 18 [15000/20177 (74%)]\tLoss: 0.671659\n",
      "Train Epoch: 18 [20000/20177 (99%)]\tLoss: 0.651730\n",
      "\n",
      "Test set: Average loss: 0.6674, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 19 [0/20177 (0%)]\tLoss: 0.611803\n",
      "Train Epoch: 19 [5000/20177 (25%)]\tLoss: 0.651702\n",
      "Train Epoch: 19 [10000/20177 (50%)]\tLoss: 0.731569\n",
      "Train Epoch: 19 [15000/20177 (74%)]\tLoss: 0.671646\n",
      "Train Epoch: 19 [20000/20177 (99%)]\tLoss: 0.651715\n",
      "\n",
      "Test set: Average loss: 0.6674, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 20 [0/20177 (0%)]\tLoss: 0.611786\n",
      "Train Epoch: 20 [5000/20177 (25%)]\tLoss: 0.651689\n",
      "Train Epoch: 20 [10000/20177 (50%)]\tLoss: 0.731561\n",
      "Train Epoch: 20 [15000/20177 (74%)]\tLoss: 0.671635\n",
      "Train Epoch: 20 [20000/20177 (99%)]\tLoss: 0.651702\n",
      "\n",
      "Test set: Average loss: 0.6673, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 21 [0/20177 (0%)]\tLoss: 0.611770\n",
      "Train Epoch: 21 [5000/20177 (25%)]\tLoss: 0.651677\n",
      "Train Epoch: 21 [10000/20177 (50%)]\tLoss: 0.731554\n",
      "Train Epoch: 21 [15000/20177 (74%)]\tLoss: 0.671625\n",
      "Train Epoch: 21 [20000/20177 (99%)]\tLoss: 0.651690\n",
      "\n",
      "Test set: Average loss: 0.6673, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 22 [0/20177 (0%)]\tLoss: 0.611756\n",
      "Train Epoch: 22 [5000/20177 (25%)]\tLoss: 0.651666\n",
      "Train Epoch: 22 [10000/20177 (50%)]\tLoss: 0.731547\n",
      "Train Epoch: 22 [15000/20177 (74%)]\tLoss: 0.671616\n",
      "Train Epoch: 22 [20000/20177 (99%)]\tLoss: 0.651679\n",
      "\n",
      "Test set: Average loss: 0.6673, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 23 [0/20177 (0%)]\tLoss: 0.611743\n",
      "Train Epoch: 23 [5000/20177 (25%)]\tLoss: 0.651656\n",
      "Train Epoch: 23 [10000/20177 (50%)]\tLoss: 0.731541\n",
      "Train Epoch: 23 [15000/20177 (74%)]\tLoss: 0.671607\n",
      "Train Epoch: 23 [20000/20177 (99%)]\tLoss: 0.651669\n",
      "\n",
      "Test set: Average loss: 0.6673, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 24 [0/20177 (0%)]\tLoss: 0.611731\n",
      "Train Epoch: 24 [5000/20177 (25%)]\tLoss: 0.651647\n",
      "Train Epoch: 24 [10000/20177 (50%)]\tLoss: 0.731535\n",
      "Train Epoch: 24 [15000/20177 (74%)]\tLoss: 0.671599\n",
      "Train Epoch: 24 [20000/20177 (99%)]\tLoss: 0.651660\n",
      "\n",
      "Test set: Average loss: 0.6673, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 25 [0/20177 (0%)]\tLoss: 0.611720\n",
      "Train Epoch: 25 [5000/20177 (25%)]\tLoss: 0.651639\n",
      "Train Epoch: 25 [10000/20177 (50%)]\tLoss: 0.731530\n",
      "Train Epoch: 25 [15000/20177 (74%)]\tLoss: 0.671592\n",
      "Train Epoch: 25 [20000/20177 (99%)]\tLoss: 0.651651\n",
      "\n",
      "Test set: Average loss: 0.6673, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 26 [0/20177 (0%)]\tLoss: 0.611710\n",
      "Train Epoch: 26 [5000/20177 (25%)]\tLoss: 0.651631\n",
      "Train Epoch: 26 [10000/20177 (50%)]\tLoss: 0.731525\n",
      "Train Epoch: 26 [15000/20177 (74%)]\tLoss: 0.671585\n",
      "Train Epoch: 26 [20000/20177 (99%)]\tLoss: 0.651644\n",
      "\n",
      "Test set: Average loss: 0.6673, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 27 [0/20177 (0%)]\tLoss: 0.611701\n",
      "Train Epoch: 27 [5000/20177 (25%)]\tLoss: 0.651624\n",
      "Train Epoch: 27 [10000/20177 (50%)]\tLoss: 0.731521\n",
      "Train Epoch: 27 [15000/20177 (74%)]\tLoss: 0.671579\n",
      "Train Epoch: 27 [20000/20177 (99%)]\tLoss: 0.651636\n",
      "\n",
      "Test set: Average loss: 0.6673, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 28 [0/20177 (0%)]\tLoss: 0.611692\n",
      "Train Epoch: 28 [5000/20177 (25%)]\tLoss: 0.651617\n",
      "Train Epoch: 28 [10000/20177 (50%)]\tLoss: 0.731516\n",
      "Train Epoch: 28 [15000/20177 (74%)]\tLoss: 0.671574\n",
      "Train Epoch: 28 [20000/20177 (99%)]\tLoss: 0.651630\n",
      "\n",
      "Test set: Average loss: 0.6673, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 29 [0/20177 (0%)]\tLoss: 0.611684\n",
      "Train Epoch: 29 [5000/20177 (25%)]\tLoss: 0.651611\n",
      "Train Epoch: 29 [10000/20177 (50%)]\tLoss: 0.731513\n",
      "Train Epoch: 29 [15000/20177 (74%)]\tLoss: 0.671568\n",
      "Train Epoch: 29 [20000/20177 (99%)]\tLoss: 0.651623\n",
      "\n",
      "Test set: Average loss: 0.6673, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 30 [0/20177 (0%)]\tLoss: 0.611676\n",
      "Train Epoch: 30 [5000/20177 (25%)]\tLoss: 0.651605\n",
      "Train Epoch: 30 [10000/20177 (50%)]\tLoss: 0.731509\n",
      "Train Epoch: 30 [15000/20177 (74%)]\tLoss: 0.671563\n",
      "Train Epoch: 30 [20000/20177 (99%)]\tLoss: 0.651617\n",
      "\n",
      "Test set: Average loss: 0.6673, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 31 [0/20177 (0%)]\tLoss: 0.611669\n",
      "Train Epoch: 31 [5000/20177 (25%)]\tLoss: 0.651600\n",
      "Train Epoch: 31 [10000/20177 (50%)]\tLoss: 0.731506\n",
      "Train Epoch: 31 [15000/20177 (74%)]\tLoss: 0.671559\n",
      "Train Epoch: 31 [20000/20177 (99%)]\tLoss: 0.651612\n",
      "\n",
      "Test set: Average loss: 0.6673, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 32 [0/20177 (0%)]\tLoss: 0.611663\n",
      "Train Epoch: 32 [5000/20177 (25%)]\tLoss: 0.651595\n",
      "Train Epoch: 32 [10000/20177 (50%)]\tLoss: 0.731503\n",
      "Train Epoch: 32 [15000/20177 (74%)]\tLoss: 0.671554\n",
      "Train Epoch: 32 [20000/20177 (99%)]\tLoss: 0.651606\n",
      "\n",
      "Test set: Average loss: 0.6673, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 33 [0/20177 (0%)]\tLoss: 0.611656\n",
      "Train Epoch: 33 [5000/20177 (25%)]\tLoss: 0.651590\n",
      "Train Epoch: 33 [10000/20177 (50%)]\tLoss: 0.731500\n",
      "Train Epoch: 33 [15000/20177 (74%)]\tLoss: 0.671550\n",
      "Train Epoch: 33 [20000/20177 (99%)]\tLoss: 0.651601\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 34 [0/20177 (0%)]\tLoss: 0.611651\n",
      "Train Epoch: 34 [5000/20177 (25%)]\tLoss: 0.651585\n",
      "Train Epoch: 34 [10000/20177 (50%)]\tLoss: 0.731497\n",
      "Train Epoch: 34 [15000/20177 (74%)]\tLoss: 0.671546\n",
      "Train Epoch: 34 [20000/20177 (99%)]\tLoss: 0.651597\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 35 [0/20177 (0%)]\tLoss: 0.611645\n",
      "Train Epoch: 35 [5000/20177 (25%)]\tLoss: 0.651581\n",
      "Train Epoch: 35 [10000/20177 (50%)]\tLoss: 0.731495\n",
      "Train Epoch: 35 [15000/20177 (74%)]\tLoss: 0.671543\n",
      "Train Epoch: 35 [20000/20177 (99%)]\tLoss: 0.651592\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 36 [0/20177 (0%)]\tLoss: 0.611640\n",
      "Train Epoch: 36 [5000/20177 (25%)]\tLoss: 0.651577\n",
      "Train Epoch: 36 [10000/20177 (50%)]\tLoss: 0.731492\n",
      "Train Epoch: 36 [15000/20177 (74%)]\tLoss: 0.671539\n",
      "Train Epoch: 36 [20000/20177 (99%)]\tLoss: 0.651588\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 37 [0/20177 (0%)]\tLoss: 0.611635\n",
      "Train Epoch: 37 [5000/20177 (25%)]\tLoss: 0.651573\n",
      "Train Epoch: 37 [10000/20177 (50%)]\tLoss: 0.731490\n",
      "Train Epoch: 37 [15000/20177 (74%)]\tLoss: 0.671536\n",
      "Train Epoch: 37 [20000/20177 (99%)]\tLoss: 0.651584\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 38 [0/20177 (0%)]\tLoss: 0.611630\n",
      "Train Epoch: 38 [5000/20177 (25%)]\tLoss: 0.651570\n",
      "Train Epoch: 38 [10000/20177 (50%)]\tLoss: 0.731488\n",
      "Train Epoch: 38 [15000/20177 (74%)]\tLoss: 0.671533\n",
      "Train Epoch: 38 [20000/20177 (99%)]\tLoss: 0.651581\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 39 [0/20177 (0%)]\tLoss: 0.611626\n",
      "Train Epoch: 39 [5000/20177 (25%)]\tLoss: 0.651567\n",
      "Train Epoch: 39 [10000/20177 (50%)]\tLoss: 0.731486\n",
      "Train Epoch: 39 [15000/20177 (74%)]\tLoss: 0.671530\n",
      "Train Epoch: 39 [20000/20177 (99%)]\tLoss: 0.651577\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 40 [0/20177 (0%)]\tLoss: 0.611622\n",
      "Train Epoch: 40 [5000/20177 (25%)]\tLoss: 0.651563\n",
      "Train Epoch: 40 [10000/20177 (50%)]\tLoss: 0.731484\n",
      "Train Epoch: 40 [15000/20177 (74%)]\tLoss: 0.671527\n",
      "Train Epoch: 40 [20000/20177 (99%)]\tLoss: 0.651574\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 41 [0/20177 (0%)]\tLoss: 0.611618\n",
      "Train Epoch: 41 [5000/20177 (25%)]\tLoss: 0.651560\n",
      "Train Epoch: 41 [10000/20177 (50%)]\tLoss: 0.731482\n",
      "Train Epoch: 41 [15000/20177 (74%)]\tLoss: 0.671525\n",
      "Train Epoch: 41 [20000/20177 (99%)]\tLoss: 0.651571\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 42 [0/20177 (0%)]\tLoss: 0.611614\n",
      "Train Epoch: 42 [5000/20177 (25%)]\tLoss: 0.651557\n",
      "Train Epoch: 42 [10000/20177 (50%)]\tLoss: 0.731480\n",
      "Train Epoch: 42 [15000/20177 (74%)]\tLoss: 0.671522\n",
      "Train Epoch: 42 [20000/20177 (99%)]\tLoss: 0.651568\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 43 [0/20177 (0%)]\tLoss: 0.611610\n",
      "Train Epoch: 43 [5000/20177 (25%)]\tLoss: 0.651555\n",
      "Train Epoch: 43 [10000/20177 (50%)]\tLoss: 0.731479\n",
      "Train Epoch: 43 [15000/20177 (74%)]\tLoss: 0.671520\n",
      "Train Epoch: 43 [20000/20177 (99%)]\tLoss: 0.651565\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 44 [0/20177 (0%)]\tLoss: 0.611607\n",
      "Train Epoch: 44 [5000/20177 (25%)]\tLoss: 0.651552\n",
      "Train Epoch: 44 [10000/20177 (50%)]\tLoss: 0.731477\n",
      "Train Epoch: 44 [15000/20177 (74%)]\tLoss: 0.671518\n",
      "Train Epoch: 44 [20000/20177 (99%)]\tLoss: 0.651562\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 45 [0/20177 (0%)]\tLoss: 0.611603\n",
      "Train Epoch: 45 [5000/20177 (25%)]\tLoss: 0.651550\n",
      "Train Epoch: 45 [10000/20177 (50%)]\tLoss: 0.731476\n",
      "Train Epoch: 45 [15000/20177 (74%)]\tLoss: 0.671515\n",
      "Train Epoch: 45 [20000/20177 (99%)]\tLoss: 0.651559\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 46 [0/20177 (0%)]\tLoss: 0.611600\n",
      "Train Epoch: 46 [5000/20177 (25%)]\tLoss: 0.651547\n",
      "Train Epoch: 46 [10000/20177 (50%)]\tLoss: 0.731474\n",
      "Train Epoch: 46 [15000/20177 (74%)]\tLoss: 0.671513\n",
      "Train Epoch: 46 [20000/20177 (99%)]\tLoss: 0.651557\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 47 [0/20177 (0%)]\tLoss: 0.611597\n",
      "Train Epoch: 47 [5000/20177 (25%)]\tLoss: 0.651545\n",
      "Train Epoch: 47 [10000/20177 (50%)]\tLoss: 0.731473\n",
      "Train Epoch: 47 [15000/20177 (74%)]\tLoss: 0.671511\n",
      "Train Epoch: 47 [20000/20177 (99%)]\tLoss: 0.651554\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 48 [0/20177 (0%)]\tLoss: 0.611594\n",
      "Train Epoch: 48 [5000/20177 (25%)]\tLoss: 0.651543\n",
      "Train Epoch: 48 [10000/20177 (50%)]\tLoss: 0.731471\n",
      "Train Epoch: 48 [15000/20177 (74%)]\tLoss: 0.671509\n",
      "Train Epoch: 48 [20000/20177 (99%)]\tLoss: 0.651552\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 49 [0/20177 (0%)]\tLoss: 0.611591\n",
      "Train Epoch: 49 [5000/20177 (25%)]\tLoss: 0.651540\n",
      "Train Epoch: 49 [10000/20177 (50%)]\tLoss: 0.731470\n",
      "Train Epoch: 49 [15000/20177 (74%)]\tLoss: 0.671508\n",
      "Train Epoch: 49 [20000/20177 (99%)]\tLoss: 0.651550\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 50 [0/20177 (0%)]\tLoss: 0.611589\n",
      "Train Epoch: 50 [5000/20177 (25%)]\tLoss: 0.651538\n",
      "Train Epoch: 50 [10000/20177 (50%)]\tLoss: 0.731469\n",
      "Train Epoch: 50 [15000/20177 (74%)]\tLoss: 0.671506\n",
      "Train Epoch: 50 [20000/20177 (99%)]\tLoss: 0.651548\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 51 [0/20177 (0%)]\tLoss: 0.611586\n",
      "Train Epoch: 51 [5000/20177 (25%)]\tLoss: 0.651536\n",
      "Train Epoch: 51 [10000/20177 (50%)]\tLoss: 0.731468\n",
      "Train Epoch: 51 [15000/20177 (74%)]\tLoss: 0.671504\n",
      "Train Epoch: 51 [20000/20177 (99%)]\tLoss: 0.651546\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 52 [0/20177 (0%)]\tLoss: 0.611584\n",
      "Train Epoch: 52 [5000/20177 (25%)]\tLoss: 0.651535\n",
      "Train Epoch: 52 [10000/20177 (50%)]\tLoss: 0.731467\n",
      "Train Epoch: 52 [15000/20177 (74%)]\tLoss: 0.671502\n",
      "Train Epoch: 52 [20000/20177 (99%)]\tLoss: 0.651543\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 53 [0/20177 (0%)]\tLoss: 0.611581\n",
      "Train Epoch: 53 [5000/20177 (25%)]\tLoss: 0.651533\n",
      "Train Epoch: 53 [10000/20177 (50%)]\tLoss: 0.731466\n",
      "Train Epoch: 53 [15000/20177 (74%)]\tLoss: 0.671501\n",
      "Train Epoch: 53 [20000/20177 (99%)]\tLoss: 0.651542\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 54 [0/20177 (0%)]\tLoss: 0.611579\n",
      "Train Epoch: 54 [5000/20177 (25%)]\tLoss: 0.651531\n",
      "Train Epoch: 54 [10000/20177 (50%)]\tLoss: 0.731465\n",
      "Train Epoch: 54 [15000/20177 (74%)]\tLoss: 0.671499\n",
      "Train Epoch: 54 [20000/20177 (99%)]\tLoss: 0.651540\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 55 [0/20177 (0%)]\tLoss: 0.611577\n",
      "Train Epoch: 55 [5000/20177 (25%)]\tLoss: 0.651529\n",
      "Train Epoch: 55 [10000/20177 (50%)]\tLoss: 0.731464\n",
      "Train Epoch: 55 [15000/20177 (74%)]\tLoss: 0.671498\n",
      "Train Epoch: 55 [20000/20177 (99%)]\tLoss: 0.651538\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 56 [0/20177 (0%)]\tLoss: 0.611575\n",
      "Train Epoch: 56 [5000/20177 (25%)]\tLoss: 0.651528\n",
      "Train Epoch: 56 [10000/20177 (50%)]\tLoss: 0.731463\n",
      "Train Epoch: 56 [15000/20177 (74%)]\tLoss: 0.671497\n",
      "Train Epoch: 56 [20000/20177 (99%)]\tLoss: 0.651536\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 57 [0/20177 (0%)]\tLoss: 0.611573\n",
      "Train Epoch: 57 [5000/20177 (25%)]\tLoss: 0.651526\n",
      "Train Epoch: 57 [10000/20177 (50%)]\tLoss: 0.731462\n",
      "Train Epoch: 57 [15000/20177 (74%)]\tLoss: 0.671495\n",
      "Train Epoch: 57 [20000/20177 (99%)]\tLoss: 0.651535\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 58 [0/20177 (0%)]\tLoss: 0.611570\n",
      "Train Epoch: 58 [5000/20177 (25%)]\tLoss: 0.651525\n",
      "Train Epoch: 58 [10000/20177 (50%)]\tLoss: 0.731461\n",
      "Train Epoch: 58 [15000/20177 (74%)]\tLoss: 0.671494\n",
      "Train Epoch: 58 [20000/20177 (99%)]\tLoss: 0.651533\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 59 [0/20177 (0%)]\tLoss: 0.611568\n",
      "Train Epoch: 59 [5000/20177 (25%)]\tLoss: 0.651523\n",
      "Train Epoch: 59 [10000/20177 (50%)]\tLoss: 0.731460\n",
      "Train Epoch: 59 [15000/20177 (74%)]\tLoss: 0.671493\n",
      "Train Epoch: 59 [20000/20177 (99%)]\tLoss: 0.651531\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 60 [0/20177 (0%)]\tLoss: 0.611567\n",
      "Train Epoch: 60 [5000/20177 (25%)]\tLoss: 0.651522\n",
      "Train Epoch: 60 [10000/20177 (50%)]\tLoss: 0.731459\n",
      "Train Epoch: 60 [15000/20177 (74%)]\tLoss: 0.671491\n",
      "Train Epoch: 60 [20000/20177 (99%)]\tLoss: 0.651530\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 61 [0/20177 (0%)]\tLoss: 0.611565\n",
      "Train Epoch: 61 [5000/20177 (25%)]\tLoss: 0.651521\n",
      "Train Epoch: 61 [10000/20177 (50%)]\tLoss: 0.731458\n",
      "Train Epoch: 61 [15000/20177 (74%)]\tLoss: 0.671490\n",
      "Train Epoch: 61 [20000/20177 (99%)]\tLoss: 0.651528\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 62 [0/20177 (0%)]\tLoss: 0.611563\n",
      "Train Epoch: 62 [5000/20177 (25%)]\tLoss: 0.651519\n",
      "Train Epoch: 62 [10000/20177 (50%)]\tLoss: 0.731458\n",
      "Train Epoch: 62 [15000/20177 (74%)]\tLoss: 0.671489\n",
      "Train Epoch: 62 [20000/20177 (99%)]\tLoss: 0.651527\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 63 [0/20177 (0%)]\tLoss: 0.611562\n",
      "Train Epoch: 63 [5000/20177 (25%)]\tLoss: 0.651518\n",
      "Train Epoch: 63 [10000/20177 (50%)]\tLoss: 0.731457\n",
      "Train Epoch: 63 [15000/20177 (74%)]\tLoss: 0.671488\n",
      "Train Epoch: 63 [20000/20177 (99%)]\tLoss: 0.651526\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 64 [0/20177 (0%)]\tLoss: 0.611560\n",
      "Train Epoch: 64 [5000/20177 (25%)]\tLoss: 0.651517\n",
      "Train Epoch: 64 [10000/20177 (50%)]\tLoss: 0.731456\n",
      "Train Epoch: 64 [15000/20177 (74%)]\tLoss: 0.671487\n",
      "Train Epoch: 64 [20000/20177 (99%)]\tLoss: 0.651524\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 65 [0/20177 (0%)]\tLoss: 0.611558\n",
      "Train Epoch: 65 [5000/20177 (25%)]\tLoss: 0.651516\n",
      "Train Epoch: 65 [10000/20177 (50%)]\tLoss: 0.731455\n",
      "Train Epoch: 65 [15000/20177 (74%)]\tLoss: 0.671486\n",
      "Train Epoch: 65 [20000/20177 (99%)]\tLoss: 0.651523\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 66 [0/20177 (0%)]\tLoss: 0.611557\n",
      "Train Epoch: 66 [5000/20177 (25%)]\tLoss: 0.651514\n",
      "Train Epoch: 66 [10000/20177 (50%)]\tLoss: 0.731455\n",
      "Train Epoch: 66 [15000/20177 (74%)]\tLoss: 0.671485\n",
      "Train Epoch: 66 [20000/20177 (99%)]\tLoss: 0.651522\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 67 [0/20177 (0%)]\tLoss: 0.611555\n",
      "Train Epoch: 67 [5000/20177 (25%)]\tLoss: 0.651513\n",
      "Train Epoch: 67 [10000/20177 (50%)]\tLoss: 0.731454\n",
      "Train Epoch: 67 [15000/20177 (74%)]\tLoss: 0.671484\n",
      "Train Epoch: 67 [20000/20177 (99%)]\tLoss: 0.651521\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 68 [0/20177 (0%)]\tLoss: 0.611554\n",
      "Train Epoch: 68 [5000/20177 (25%)]\tLoss: 0.651512\n",
      "Train Epoch: 68 [10000/20177 (50%)]\tLoss: 0.731453\n",
      "Train Epoch: 68 [15000/20177 (74%)]\tLoss: 0.671483\n",
      "Train Epoch: 68 [20000/20177 (99%)]\tLoss: 0.651519\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 69 [0/20177 (0%)]\tLoss: 0.611552\n",
      "Train Epoch: 69 [5000/20177 (25%)]\tLoss: 0.651511\n",
      "Train Epoch: 69 [10000/20177 (50%)]\tLoss: 0.731453\n",
      "Train Epoch: 69 [15000/20177 (74%)]\tLoss: 0.671482\n",
      "Train Epoch: 69 [20000/20177 (99%)]\tLoss: 0.651518\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 70 [0/20177 (0%)]\tLoss: 0.611551\n",
      "Train Epoch: 70 [5000/20177 (25%)]\tLoss: 0.651510\n",
      "Train Epoch: 70 [10000/20177 (50%)]\tLoss: 0.731452\n",
      "Train Epoch: 70 [15000/20177 (74%)]\tLoss: 0.671481\n",
      "Train Epoch: 70 [20000/20177 (99%)]\tLoss: 0.651517\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 71 [0/20177 (0%)]\tLoss: 0.611550\n",
      "Train Epoch: 71 [5000/20177 (25%)]\tLoss: 0.651509\n",
      "Train Epoch: 71 [10000/20177 (50%)]\tLoss: 0.731452\n",
      "Train Epoch: 71 [15000/20177 (74%)]\tLoss: 0.671480\n",
      "Train Epoch: 71 [20000/20177 (99%)]\tLoss: 0.651516\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 72 [0/20177 (0%)]\tLoss: 0.611548\n",
      "Train Epoch: 72 [5000/20177 (25%)]\tLoss: 0.651508\n",
      "Train Epoch: 72 [10000/20177 (50%)]\tLoss: 0.731451\n",
      "Train Epoch: 72 [15000/20177 (74%)]\tLoss: 0.671479\n",
      "Train Epoch: 72 [20000/20177 (99%)]\tLoss: 0.651515\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 73 [0/20177 (0%)]\tLoss: 0.611547\n",
      "Train Epoch: 73 [5000/20177 (25%)]\tLoss: 0.651507\n",
      "Train Epoch: 73 [10000/20177 (50%)]\tLoss: 0.731450\n",
      "Train Epoch: 73 [15000/20177 (74%)]\tLoss: 0.671478\n",
      "Train Epoch: 73 [20000/20177 (99%)]\tLoss: 0.651514\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 74 [0/20177 (0%)]\tLoss: 0.611546\n",
      "Train Epoch: 74 [5000/20177 (25%)]\tLoss: 0.651506\n",
      "Train Epoch: 74 [10000/20177 (50%)]\tLoss: 0.731450\n",
      "Train Epoch: 74 [15000/20177 (74%)]\tLoss: 0.671478\n",
      "Train Epoch: 74 [20000/20177 (99%)]\tLoss: 0.651513\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 75 [0/20177 (0%)]\tLoss: 0.611545\n",
      "Train Epoch: 75 [5000/20177 (25%)]\tLoss: 0.651506\n",
      "Train Epoch: 75 [10000/20177 (50%)]\tLoss: 0.731449\n",
      "Train Epoch: 75 [15000/20177 (74%)]\tLoss: 0.671477\n",
      "Train Epoch: 75 [20000/20177 (99%)]\tLoss: 0.651512\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 76 [0/20177 (0%)]\tLoss: 0.611544\n",
      "Train Epoch: 76 [5000/20177 (25%)]\tLoss: 0.651505\n",
      "Train Epoch: 76 [10000/20177 (50%)]\tLoss: 0.731449\n",
      "Train Epoch: 76 [15000/20177 (74%)]\tLoss: 0.671476\n",
      "Train Epoch: 76 [20000/20177 (99%)]\tLoss: 0.651511\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 77 [0/20177 (0%)]\tLoss: 0.611543\n",
      "Train Epoch: 77 [5000/20177 (25%)]\tLoss: 0.651504\n",
      "Train Epoch: 77 [10000/20177 (50%)]\tLoss: 0.731448\n",
      "Train Epoch: 77 [15000/20177 (74%)]\tLoss: 0.671475\n",
      "Train Epoch: 77 [20000/20177 (99%)]\tLoss: 0.651510\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 78 [0/20177 (0%)]\tLoss: 0.611541\n",
      "Train Epoch: 78 [5000/20177 (25%)]\tLoss: 0.651503\n",
      "Train Epoch: 78 [10000/20177 (50%)]\tLoss: 0.731448\n",
      "Train Epoch: 78 [15000/20177 (74%)]\tLoss: 0.671475\n",
      "Train Epoch: 78 [20000/20177 (99%)]\tLoss: 0.651509\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 79 [0/20177 (0%)]\tLoss: 0.611540\n",
      "Train Epoch: 79 [5000/20177 (25%)]\tLoss: 0.651502\n",
      "Train Epoch: 79 [10000/20177 (50%)]\tLoss: 0.731447\n",
      "Train Epoch: 79 [15000/20177 (74%)]\tLoss: 0.671474\n",
      "Train Epoch: 79 [20000/20177 (99%)]\tLoss: 0.651509\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 80 [0/20177 (0%)]\tLoss: 0.611539\n",
      "Train Epoch: 80 [5000/20177 (25%)]\tLoss: 0.651501\n",
      "Train Epoch: 80 [10000/20177 (50%)]\tLoss: 0.731447\n",
      "Train Epoch: 80 [15000/20177 (74%)]\tLoss: 0.671473\n",
      "Train Epoch: 80 [20000/20177 (99%)]\tLoss: 0.651508\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 81 [0/20177 (0%)]\tLoss: 0.611538\n",
      "Train Epoch: 81 [5000/20177 (25%)]\tLoss: 0.651501\n",
      "Train Epoch: 81 [10000/20177 (50%)]\tLoss: 0.731446\n",
      "Train Epoch: 81 [15000/20177 (74%)]\tLoss: 0.671472\n",
      "Train Epoch: 81 [20000/20177 (99%)]\tLoss: 0.651507\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 82 [0/20177 (0%)]\tLoss: 0.611537\n",
      "Train Epoch: 82 [5000/20177 (25%)]\tLoss: 0.651500\n",
      "Train Epoch: 82 [10000/20177 (50%)]\tLoss: 0.731446\n",
      "Train Epoch: 82 [15000/20177 (74%)]\tLoss: 0.671472\n",
      "Train Epoch: 82 [20000/20177 (99%)]\tLoss: 0.651506\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 83 [0/20177 (0%)]\tLoss: 0.611536\n",
      "Train Epoch: 83 [5000/20177 (25%)]\tLoss: 0.651499\n",
      "Train Epoch: 83 [10000/20177 (50%)]\tLoss: 0.731445\n",
      "Train Epoch: 83 [15000/20177 (74%)]\tLoss: 0.671471\n",
      "Train Epoch: 83 [20000/20177 (99%)]\tLoss: 0.651505\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 84 [0/20177 (0%)]\tLoss: 0.611535\n",
      "Train Epoch: 84 [5000/20177 (25%)]\tLoss: 0.651499\n",
      "Train Epoch: 84 [10000/20177 (50%)]\tLoss: 0.731445\n",
      "Train Epoch: 84 [15000/20177 (74%)]\tLoss: 0.671470\n",
      "Train Epoch: 84 [20000/20177 (99%)]\tLoss: 0.651504\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 85 [0/20177 (0%)]\tLoss: 0.611534\n",
      "Train Epoch: 85 [5000/20177 (25%)]\tLoss: 0.651498\n",
      "Train Epoch: 85 [10000/20177 (50%)]\tLoss: 0.731445\n",
      "Train Epoch: 85 [15000/20177 (74%)]\tLoss: 0.671470\n",
      "Train Epoch: 85 [20000/20177 (99%)]\tLoss: 0.651504\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 86 [0/20177 (0%)]\tLoss: 0.611534\n",
      "Train Epoch: 86 [5000/20177 (25%)]\tLoss: 0.651497\n",
      "Train Epoch: 86 [10000/20177 (50%)]\tLoss: 0.731444\n",
      "Train Epoch: 86 [15000/20177 (74%)]\tLoss: 0.671469\n",
      "Train Epoch: 86 [20000/20177 (99%)]\tLoss: 0.651503\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 87 [0/20177 (0%)]\tLoss: 0.611533\n",
      "Train Epoch: 87 [5000/20177 (25%)]\tLoss: 0.651497\n",
      "Train Epoch: 87 [10000/20177 (50%)]\tLoss: 0.731444\n",
      "Train Epoch: 87 [15000/20177 (74%)]\tLoss: 0.671469\n",
      "Train Epoch: 87 [20000/20177 (99%)]\tLoss: 0.651502\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 88 [0/20177 (0%)]\tLoss: 0.611532\n",
      "Train Epoch: 88 [5000/20177 (25%)]\tLoss: 0.651496\n",
      "Train Epoch: 88 [10000/20177 (50%)]\tLoss: 0.731443\n",
      "Train Epoch: 88 [15000/20177 (74%)]\tLoss: 0.671468\n",
      "Train Epoch: 88 [20000/20177 (99%)]\tLoss: 0.651502\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 89 [0/20177 (0%)]\tLoss: 0.611531\n",
      "Train Epoch: 89 [5000/20177 (25%)]\tLoss: 0.651495\n",
      "Train Epoch: 89 [10000/20177 (50%)]\tLoss: 0.731443\n",
      "Train Epoch: 89 [15000/20177 (74%)]\tLoss: 0.671467\n",
      "Train Epoch: 89 [20000/20177 (99%)]\tLoss: 0.651501\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 90 [0/20177 (0%)]\tLoss: 0.611530\n",
      "Train Epoch: 90 [5000/20177 (25%)]\tLoss: 0.651495\n",
      "Train Epoch: 90 [10000/20177 (50%)]\tLoss: 0.731443\n",
      "Train Epoch: 90 [15000/20177 (74%)]\tLoss: 0.671467\n",
      "Train Epoch: 90 [20000/20177 (99%)]\tLoss: 0.651500\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 91 [0/20177 (0%)]\tLoss: 0.611529\n",
      "Train Epoch: 91 [5000/20177 (25%)]\tLoss: 0.651494\n",
      "Train Epoch: 91 [10000/20177 (50%)]\tLoss: 0.731442\n",
      "Train Epoch: 91 [15000/20177 (74%)]\tLoss: 0.671466\n",
      "Train Epoch: 91 [20000/20177 (99%)]\tLoss: 0.651500\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 92 [0/20177 (0%)]\tLoss: 0.611529\n",
      "Train Epoch: 92 [5000/20177 (25%)]\tLoss: 0.651494\n",
      "Train Epoch: 92 [10000/20177 (50%)]\tLoss: 0.731442\n",
      "Train Epoch: 92 [15000/20177 (74%)]\tLoss: 0.671466\n",
      "Train Epoch: 92 [20000/20177 (99%)]\tLoss: 0.651499\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 93 [0/20177 (0%)]\tLoss: 0.611528\n",
      "Train Epoch: 93 [5000/20177 (25%)]\tLoss: 0.651493\n",
      "Train Epoch: 93 [10000/20177 (50%)]\tLoss: 0.731441\n",
      "Train Epoch: 93 [15000/20177 (74%)]\tLoss: 0.671465\n",
      "Train Epoch: 93 [20000/20177 (99%)]\tLoss: 0.651498\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 94 [0/20177 (0%)]\tLoss: 0.611527\n",
      "Train Epoch: 94 [5000/20177 (25%)]\tLoss: 0.651492\n",
      "Train Epoch: 94 [10000/20177 (50%)]\tLoss: 0.731441\n",
      "Train Epoch: 94 [15000/20177 (74%)]\tLoss: 0.671465\n",
      "Train Epoch: 94 [20000/20177 (99%)]\tLoss: 0.651498\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 95 [0/20177 (0%)]\tLoss: 0.611526\n",
      "Train Epoch: 95 [5000/20177 (25%)]\tLoss: 0.651492\n",
      "Train Epoch: 95 [10000/20177 (50%)]\tLoss: 0.731441\n",
      "Train Epoch: 95 [15000/20177 (74%)]\tLoss: 0.671464\n",
      "Train Epoch: 95 [20000/20177 (99%)]\tLoss: 0.651497\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 96 [0/20177 (0%)]\tLoss: 0.611526\n",
      "Train Epoch: 96 [5000/20177 (25%)]\tLoss: 0.651491\n",
      "Train Epoch: 96 [10000/20177 (50%)]\tLoss: 0.731440\n",
      "Train Epoch: 96 [15000/20177 (74%)]\tLoss: 0.671464\n",
      "Train Epoch: 96 [20000/20177 (99%)]\tLoss: 0.651496\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 97 [0/20177 (0%)]\tLoss: 0.611525\n",
      "Train Epoch: 97 [5000/20177 (25%)]\tLoss: 0.651491\n",
      "Train Epoch: 97 [10000/20177 (50%)]\tLoss: 0.731440\n",
      "Train Epoch: 97 [15000/20177 (74%)]\tLoss: 0.671463\n",
      "Train Epoch: 97 [20000/20177 (99%)]\tLoss: 0.651496\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 98 [0/20177 (0%)]\tLoss: 0.611524\n",
      "Train Epoch: 98 [5000/20177 (25%)]\tLoss: 0.651490\n",
      "Train Epoch: 98 [10000/20177 (50%)]\tLoss: 0.731440\n",
      "Train Epoch: 98 [15000/20177 (74%)]\tLoss: 0.671463\n",
      "Train Epoch: 98 [20000/20177 (99%)]\tLoss: 0.651495\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n",
      "Number of parameters: 243\n",
      "Train Epoch: 99 [0/20177 (0%)]\tLoss: 0.611524\n",
      "Train Epoch: 99 [5000/20177 (25%)]\tLoss: 0.651490\n",
      "Train Epoch: 99 [10000/20177 (50%)]\tLoss: 0.731439\n",
      "Train Epoch: 99 [15000/20177 (74%)]\tLoss: 0.671462\n",
      "Train Epoch: 99 [20000/20177 (99%)]\tLoss: 0.651495\n",
      "\n",
      "Test set: Average loss: 0.6672, Accuracy:     5948/6726 (88%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create nn instance\n",
    "BaseNN = BaseMLP(8, 20, 3)\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    train(epoch, BaseNN)\n",
    "    test(BaseNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2bc373eb9924f1eec97d7a15274cdae8484277ec408c67c247974831754df4b1"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('PHYS555_PY37')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
